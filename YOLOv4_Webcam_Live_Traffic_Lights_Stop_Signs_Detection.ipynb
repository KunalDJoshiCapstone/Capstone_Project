{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv4_Webcam_Live_Traffic_Lights_Stop_Signs_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjlJ0zSrkQnQ"
      },
      "source": [
        "#Reference note:- Commands between steps 2 to 9 have been referred from the website https://colab.research.google.com/drive/1zqRb08ljHvIIMR4fgAXeNy1kUtjDU85B?usp=sharing. Program in step 10 is the program for real time object detection and recognition using webcam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TccE7bFubOM"
      },
      "source": [
        "#1)In your drive, create the folders namely yolov4 and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9-tYD-UuVv0"
      },
      "source": [
        "#2) Mount drive, link your folder and navigate to /mydrive/yolov4 folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsGejOzluOLM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj0r3dQHulI7"
      },
      "source": [
        "#mount drive\n",
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "\n",
        "# list the contents of /mydrive\n",
        "!ls /mydrive\n",
        "\n",
        "#Navigate to /mydrive/yolov4\n",
        "%cd /mydrive/yolov4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4MZEHBuu-LI"
      },
      "source": [
        "# 3) Clone the git repository of darknet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EApR9DBh0rLI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbIqY6ovEhb"
      },
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XicVPmFj0ulg"
      },
      "source": [
        "# 4) For training a custom object detector, create and upload the following files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpeEA96nKCHT"
      },
      "source": [
        "# 4(a) Upload the obj.zip file consisting of labeled custom dataset to the yolov4 folder on your drive\n",
        "# 4(b) A config file should be create and upload on the drive\n",
        "# 4(c) obj.names and obj.data files should be create and upload on the drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbwOeu-xKUjt"
      },
      "source": [
        "# 5) Run below commands to enable OPENCV and GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWhHODUEKSVe"
      },
      "source": [
        "\n",
        "%cd darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HfRyUhrKfH6"
      },
      "source": [
        "# 6) Run make command to build darknet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrZ8Kvm1Kj9f"
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpZclSTANNgf"
      },
      "source": [
        "# 7) Copy all the files from the yolov4 folder to the darknet directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFFaCjZPNWa2"
      },
      "source": [
        "\n",
        "%cd data/\n",
        "!find -maxdepth 1 -type f -exec rm -rf {} \\;\n",
        "%cd ..\n",
        "\n",
        "%rm -rf cfg/\n",
        "%mkdir cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zeEW13CNmvK"
      },
      "source": [
        "\n",
        "!unzip /mydrive/yolov4/obj.zip -d data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0rfkaBYNxbe"
      },
      "source": [
        "# Copy the yolov4-custom.cfg file so that it is now in /darknet/cfg/ folder \n",
        "\n",
        "!cp /mydrive/yolov4/yolov4-custom.cfg cfg\n",
        "\n",
        "# verify if your custom file is in cfg folder\n",
        "!ls cfg/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBWm0O6XN74_",
        "outputId": "80863ee3-cbc1-4631-861c-e58c441ac392"
      },
      "source": [
        "# Copy the obj.names and obj.data files from your drive so that they are now in /darknet/data/ folder \n",
        "\n",
        "!cp /mydrive/yolov4/obj.names data\n",
        "!cp /mydrive/yolov4/obj.data  data\n",
        "\n",
        "# verify if the above files are in data folder\n",
        "!ls data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels\tobj  obj.data  obj.names\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3mDULiLOWMI"
      },
      "source": [
        "# Copy the process.py file to the current darknet directory \n",
        "\n",
        "!cp /mydrive/yolov4/process.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2eStQOQQQ4A"
      },
      "source": [
        "# 8) Run the below command in order to download the pretrained weights of the YOLO v4 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw2CVuM4QS0C"
      },
      "source": [
        "# Download the yolov4 pre-trained weights file\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoZMdEkzQwrA"
      },
      "source": [
        "# 9) Run below command to Train your YOLO v4 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5-9ctd7Qxx1"
      },
      "source": [
        "\n",
        "!./darknet detector train data/obj.data cfg/yolov4-custom.cfg yolov4.conv.137 -dont_show -map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRs9oBCNOTzY"
      },
      "source": [
        "#10) Program for real time traffic lights and stop signs detections using live webcam streaming "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2hxsjwzE_RJ"
      },
      "source": [
        "#all the required libraries are imported\n",
        "from IPython.display import display, HTML,Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import json\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from darknet import *\n",
        "%matplotlib inline\n",
        "\n",
        "#HTML document type is passed as a string parameter to HTML function. HTML function is called inside the display function. \n",
        "display(HTML('''\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "  <script>\n",
        "//all required variables are declared here     \n",
        "var videoStream;\n",
        "var clearHandle;\n",
        "var frameCount = 0;\n",
        "var currFrame;\n",
        "var width = 0;\n",
        "var height = 0;\n",
        "var videoElement;\n",
        "var canvasElement;\n",
        "var containerElement;\n",
        "var streaming = false;\n",
        "var prevbboxes = [];\n",
        "var detectionsDiv;\n",
        "var stopRequested = false;\n",
        "\n",
        "//streamVideo() gets invoked when Start Video button is clicked. This starts the webcam of the machine.\n",
        "function streamVideo() {\n",
        "    videoElement = document.getElementById(\"videoElement\");\n",
        "    canvasElement = document.getElementById(\"canvas\");\n",
        "    containerElement = document.getElementById(\"container\");\n",
        "\n",
        "    if (navigator.mediaDevices.getUserMedia) {\n",
        "        navigator.mediaDevices.getUserMedia({ video: {facingMode: \"environment\"}, audio: false })\n",
        "        .then(function (stream) {\n",
        "                videoElement.srcObject = stream;\n",
        "                videoStream = stream;\n",
        "            videoElement.play();\n",
        "        })\n",
        "        .catch(function (error) {\n",
        "            console.log(\"video failed with error: \" + error);\n",
        "        });\n",
        "    }\n",
        "\n",
        "//addEventListener() function handles events when any button is clicked. \n",
        "    videoElement.addEventListener('canplay', function(ev) {\n",
        "      if (!streaming) {\n",
        "        console.log(videoElement.videoHeight, videoElement.videoWidth);\n",
        "        height = videoElement.videoHeight; \n",
        "        width = videoElement.videoWidth;\n",
        "        containerElement.style.width = width+ \"px\";\n",
        "        containerElement.style.height = height + \"px\";\n",
        "        videoElement.style.width = width + \"px\";\n",
        "        videoElement.style.height = height + \"px\";\n",
        "        canvasElement.style.width = width + \"px\";\n",
        "        canvasElement.style.height = height + \"px\";\n",
        "        streaming = true;\n",
        "      }\n",
        "    }, false)\n",
        "}\n",
        "\n",
        "//stopVideo() function gets invoked when stop video button is pressed.\n",
        "function stopVideo() {\n",
        "    videoStream.getTracks().forEach(function(track) {\n",
        "        track.stop();\n",
        "    });\n",
        "}\n",
        "\n",
        "//saveVideoFrames() function saves the video frames captured by the webcam. When Start Capture button is pressed after starting webcam, \n",
        "//video frames are saved after every 5 ms interval.\n",
        "function saveVideoFrames() {\n",
        "  if (stopRequested) {\n",
        "    currFrame = null\n",
        "    return\n",
        "  }\n",
        "  var context = canvasElement.getContext('2d');\n",
        "  console.log(\"using width \", width, \" height \", height)\n",
        "  canvasElement.width = width;\n",
        "  canvasElement.height = height;\n",
        "  context.drawImage(videoElement, 0, 0, width, height);\n",
        "  var data = canvasElement.toDataURL('image/jpeg', 0.8);\n",
        "  currFrame = data;\n",
        "}\n",
        "\n",
        "//startSavingVideoFrames() function gets invoked when Start Capture button is pressed.\n",
        "function startSavingVideoFrames() {\n",
        "  clearHandle = setInterval(saveVideoFrames, 5);\n",
        "}\n",
        "\n",
        "//stopSavingVideoFrames( ) function gets invoked when Stop Capture button is pressed.\n",
        "function stopSavingVideoFrames( ) {\n",
        "  clearInterval(clearHandle);\n",
        "  stopRequested = true;\n",
        "}\n",
        "\n",
        "//removeboxfromvideo() is called from createdetectoinbboxes(). It removes the previuos bounding boxes. \n",
        "function removeboxfromvideo() {\n",
        "  for (let i = 0; i < prevbboxes.length; i++) {\n",
        "      prevbboxes[i].remove();\n",
        "  }\n",
        "  prevbboxes = [];\n",
        "}\n",
        "\n",
        "//createdetectoinbboxes() function accepts 3 parameters objects data in json format, its weidth ratio and height ratio\n",
        "function createdetectoinbboxes(data, wr, hr) {\n",
        "    removeboxfromvideo();\n",
        "    var detections = JSON.parse(data);\n",
        "    for (let i = 0; i < detections.length; i++) {\n",
        "      var det = detections[i][2];\n",
        "      var accuracy = parseFloat(det[i][1]);\n",
        "      createbbox(detections[i][0], detections[i][1], det[0], det[2], det[1], det[3]);\n",
        "    }\n",
        "}\n",
        "\n",
        "//createbbox() accepts 6 parameters. type of object i.e., traffic light or stop sign, accuracy, x coordinate, y coordinate, width and height.\n",
        "//This function creates bounding boxes along with class label and accuracies.\n",
        "function createbbox(type, accuracy, startx, starty, w, h) {\n",
        "    detectionsDiv = document.getElementById(\"detections\");\n",
        "    var idiv = document.createElement('div');\n",
        "    var labdiv = document.createElement('label');\n",
        "    labdiv.style.color = \"red\";\n",
        "    labdiv.innerText = type + \" \" + accuracy;\n",
        "\n",
        "    idiv.className = 'box'\n",
        "    idiv.style.width = w + \"px\";\n",
        "    idiv.style.height = h + \"px\";\n",
        "    idiv.style.left = startx + \"px\";\n",
        "    idiv.style.top = starty + \"px\";\n",
        "    idiv.appendChild(labdiv);\n",
        "    detectionsDiv.appendChild(idiv);\n",
        "    prevbboxes.push(idiv);\n",
        "}\n",
        "\n",
        "function setdebugimg(data) {\n",
        "  var image = new Image();\n",
        "  image.src = data;\n",
        "  image.width = width;\n",
        "  image.height = height;\n",
        "  debugDiv = document.getElementById(\"debug\");\n",
        "  debugDiv.appendChild(image);\n",
        "}\n",
        "\n",
        "//getFrameAndClear() calls removeboxfromvideo() which removes the previuos bounding boxes and return current frame.\n",
        "function getFrameAndClear() {\n",
        "  removeboxfromvideo()\n",
        "  return currFrame;\n",
        "}\n",
        "\n",
        "  </script>\n",
        "  <head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <title>Display Webcam Stream</title>\n",
        "\n",
        "    <style>\n",
        "      #container {\n",
        "        margin: 0px;\n",
        "        width: 400px;\n",
        "        height: 400px;\n",
        "        border: 10px #333 solid;\n",
        "      }\n",
        "      #videoElement {\n",
        "        position: absolute;\n",
        "        width: 400px;\n",
        "        height: 400px;\n",
        "        background-color: #666;\n",
        "      }\n",
        "      #detections: {\n",
        "        position: absolute;\n",
        "      }\n",
        "      #canvas {\n",
        "        display: none;\n",
        "      }\n",
        "      .box {\n",
        "        position: absolute;\n",
        "        z-index: 1000;\n",
        "        border: solid 3px green;\n",
        "      }\n",
        "    </style>\n",
        "  </head>\n",
        "\n",
        "  <body>\n",
        "    <canvas id=\"canvas\"></canvas>\n",
        "    <div id=\"container\"> \n",
        "      <div id=\"detections\">\n",
        "      <video autoplay=\"true\" id=\"videoElement\"></video>\n",
        "      <div class=\"box\"></div>\n",
        "      </div>\n",
        "    </div>\n",
        "    <div id=\"debug\">\n",
        "    </div>\n",
        "    <div id=\"control\">\n",
        "      <button onClick=streamVideo() id=\"startVideo\"> Start Video </button>\n",
        "      <button onClick=stopVideo() id=\"stopVideo\"> Stop Video </button>\n",
        "      <br/>\n",
        "      <button onClick=startSavingVideoFrames() id=\"startCapture\"> Start Capture </button>\n",
        "      <button onClick=stopSavingVideoFrames() id=\"stopCapture\"> Stop Capture </button>\n",
        "    </div>\n",
        "    <script>\n",
        "\n",
        "    </script>\n",
        "  </body>\n",
        "</html>\n",
        "\n",
        "'''))\n",
        "\n",
        "#load network function accepts parameters namely config file, data file and weights of the trained model.\n",
        "network, class_names, class_colors = load_network(\"cfg/yolov4-custom.cfg\", \"data/obj.data\", \"/mydrive/yolov4/training/yolov4-custom_best.weights\")\n",
        "nwidth = network_width(network)\n",
        "nheight = network_height(network)\n",
        "img_height = 0;\n",
        "img_width = 0;\n",
        "#By using eval_js() python function, we can call JavaScript functions through Python program.\n",
        "while True:\n",
        "    cf = eval_js('getFrameAndClear()')\n",
        "    if cf is None:\n",
        "      continue\n",
        "    decoded_img = b64decode(cf.split(',')[1])\n",
        "    imgnparr = np.frombuffer(decoded_img, dtype=np.uint8)\n",
        "    cvimg = cv2.imdecode(imgnparr, 1)\n",
        "    img_rgb = cv2.cvtColor(cvimg, cv2.COLOR_BGR2RGB)\n",
        "    img_resized = cv2.resize(img_rgb, (nwidth, nheight),\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "    \n",
        "    retval, buffer = cv2.imencode('.jpeg', img_resized)\n",
        "    jpeg_as_text = b64encode(buffer)\n",
        "    jat = 'data:image/png;base64,' + jpeg_as_text.decode('utf-8')\n",
        "\n",
        "\n",
        "    # get image ratios to convert bounding boxes to proper size\n",
        "    if img_height == 0:\n",
        "      img_height = eval_js('height')\n",
        "    if img_width == 0:\n",
        "      img_width = eval_js('width')\n",
        "    width_ratio = img_width/nwidth\n",
        "    height_ratio = img_height/nheight\n",
        "\n",
        "    # run model on darknet style image to get detections\n",
        "    darknet_image = make_image(nwidth, nheight, 3)\n",
        "    copy_image_from_bytes(darknet_image, img_resized.tobytes())\n",
        "    detections = detect_image(network, class_names, darknet_image)\n",
        "    free_image(darknet_image)\n",
        "\n",
        "    \n",
        "    if len(detections) > 0:\n",
        "      newdets = []\n",
        "      for det in detections:\n",
        "        xmin, ymin, xmax, ymax = bbox2points(det[2])\n",
        "        xmin, ymin, xmax, ymax = int(xmin * width_ratio), int(ymin * height_ratio), int(xmax * width_ratio), int(ymax * height_ratio)\n",
        "        newdets.append((det[0], det[1], (xmin, (xmax - xmin), ymin, (ymax - ymin))))\n",
        "      eval_js('createdetectoinbboxes(\\' {} \\', {}, {})'.format(json.dumps(newdets), width_ratio, height_ratio))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}